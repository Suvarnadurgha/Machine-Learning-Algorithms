{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQl-CmTXZtIX",
        "outputId": "06fb473f-e7b7-4e6c-e63b-a9eb89c18a9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data (First 5 rows):\n",
            "   OBS_ID  CHK_ACCT  DURATION  HISTORY  NEW_CAR  USED_CAR  FURNITURE  \\\n",
            "0     860         3         9        2        1         0          0   \n",
            "1     704         1        30        3        0         0          0   \n",
            "2     791         1        21        2        0         0          0   \n",
            "3     385         3        30        3        0         0          0   \n",
            "4     406         1        24        2        0         0          0   \n",
            "\n",
            "   RADIO/TV  EDUCATION  RETRAINING  ...  AGE  OTHER_INSTALL  RENT  OWN_RES  \\\n",
            "0         0          0           0  ...   26              0     1        0   \n",
            "1         0          0           1  ...   41              1     0        1   \n",
            "2         0          0           1  ...   39              0     0        1   \n",
            "3         0          0           1  ...   26              0     0        1   \n",
            "4         1          0           0  ...   22              0     0        1   \n",
            "\n",
            "   NUM_CREDITS  JOB  NUM_DEPENDENTS  TELEPHONE  FOREIGN  RESPONSE  \n",
            "0            1    2               2          0        1         1  \n",
            "1            2    2               1          0        0         1  \n",
            "2            1    2               2          0        0         0  \n",
            "3            2    1               1          0        0         1  \n",
            "4            1    2               1          1        0         0  \n",
            "\n",
            "[5 rows x 32 columns]\n",
            "\n",
            "Testing Data (First 5 rows):\n",
            "   OBS_ID  CHK_ACCT  DURATION  HISTORY  NEW_CAR  USED_CAR  FURNITURE  \\\n",
            "0     890         3        28        1        0         1          0   \n",
            "1     140         2        12        2        0         0          0   \n",
            "2     594         1        24        2        1         0          0   \n",
            "3     772         0        36        4        0         0          0   \n",
            "4     609         3        18        2        0         0          0   \n",
            "\n",
            "   RADIO/TV  EDUCATION  RETRAINING  ...  PROP_UNKN_NONE  AGE  OTHER_INSTALL  \\\n",
            "0         0          0           0  ...               0   40              1   \n",
            "1         1          0           0  ...               0   44              0   \n",
            "2         0          0           0  ...               0   20              0   \n",
            "3         0          1           0  ...               1   25              0   \n",
            "4         1          0           0  ...               0   33              0   \n",
            "\n",
            "   RENT  OWN_RES  NUM_CREDITS  JOB  NUM_DEPENDENTS  TELEPHONE  FOREIGN  \n",
            "0     1        0            2    2               2          1        0  \n",
            "1     1        0            1    1               1          1        0  \n",
            "2     1        0            1    1               1          1        0  \n",
            "3     0        1            2    3               1          1        0  \n",
            "4     0        1            1    2               1          0        0  \n",
            "\n",
            "[5 rows x 31 columns]\n",
            "\n",
            "Data after dropping missing values (First 5 rows):\n",
            "   OBS_ID\n",
            "0     860\n",
            "1     704\n",
            "2     791\n",
            "3     385\n",
            "4     406\n",
            "\n",
            "Features (First 5 rows):\n",
            "   CHK_ACCT  DURATION  HISTORY  NEW_CAR  USED_CAR  FURNITURE  RADIO/TV  \\\n",
            "0         3         9        2        1         0          0         0   \n",
            "1         1        30        3        0         0          0         0   \n",
            "2         1        21        2        0         0          0         0   \n",
            "3         3        30        3        0         0          0         0   \n",
            "4         1        24        2        0         0          0         1   \n",
            "\n",
            "   EDUCATION  RETRAINING  \n",
            "0          0           0  \n",
            "1          0           1  \n",
            "2          0           1  \n",
            "3          0           1  \n",
            "4          0           0  \n",
            "\n",
            "Target variable (First 5 rows):\n",
            "0    1\n",
            "1    1\n",
            "2    0\n",
            "3    1\n",
            "4    0\n",
            "Name: RESPONSE, dtype: int64\n",
            "\n",
            "X_train shape: (630, 9)\n",
            "X_test shape: (70, 9)\n",
            "y_train shape: (630,)\n",
            "y_test shape: (70,)\n",
            "\n",
            "Scaled Training Features (First 5 rows):\n",
            "[[-0.44659741 -0.75801888 -0.50561146 -0.56146245 -0.31843147  2.10500225\n",
            "  -0.63491577 -0.2388451  -0.32144595]\n",
            " [-1.23915057 -0.244246   -0.50561146  1.78106301 -0.31843147 -0.47505887\n",
            "  -0.63491577 -0.2388451  -0.32144595]\n",
            " [ 0.34595574  0.78329977  1.30424773 -0.56146245 -0.31843147 -0.47505887\n",
            "   1.57501206 -0.2388451  -0.32144595]\n",
            " [-1.23915057 -1.27179176 -0.50561146 -0.56146245 -0.31843147 -0.47505887\n",
            "   1.57501206 -0.2388451  -0.32144595]\n",
            " [ 1.1385089  -0.244246    1.30424773 -0.56146245 -0.31843147  2.10500225\n",
            "  -0.63491577 -0.2388451  -0.32144595]]\n",
            "\n",
            "Best Hyperparameters:\n",
            "{'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 100}\n",
            "\n",
            "Accuracy: 0.7\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.54      0.55        24\n",
            "           1       0.77      0.78      0.77        46\n",
            "\n",
            "    accuracy                           0.70        70\n",
            "   macro avg       0.67      0.66      0.66        70\n",
            "weighted avg       0.70      0.70      0.70        70\n",
            "\n",
            "\n",
            "Predictions on Testing Data (First 5 rows):\n",
            "    ID  score_level\n",
            "0  890            1\n",
            "1  140            1\n",
            "2  594            0\n",
            "3  772            0\n",
            "4  609            1\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Step 1: Load the training data\n",
        "path = 'credit_training.csv'\n",
        "df = pd.read_csv(path, sep=',', encoding='ISO-8859-1', quotechar='\"', nrows=1000)\n",
        "\n",
        "# Display the first few rows of the training data\n",
        "print(\"Training Data (First 5 rows):\")\n",
        "print(df.head())\n",
        "\n",
        "# Step 2: Load the testing data\n",
        "testing_path = 'credit_testing.csv'\n",
        "testing_data = pd.read_csv(testing_path, sep=',', encoding='ISO-8859-1', quotechar='\"')\n",
        "\n",
        "# Display the first few rows of the testing data\n",
        "print(\"\\nTesting Data (First 5 rows):\")\n",
        "print(testing_data.head())\n",
        "\n",
        "# Step 3: Keep only the required fields (just showing that it is kept)\n",
        "data = df[['OBS_ID']]\n",
        "\n",
        "# Step 4: Drop rows with missing values\n",
        "data = data.dropna()\n",
        "\n",
        "# Display rows without missing values\n",
        "print(\"\\nData after dropping missing values (First 5 rows):\")\n",
        "print(data.head())\n",
        "\n",
        "# Step 5: Extract features and target variable\n",
        "X_train = df[['CHK_ACCT', 'DURATION', 'HISTORY', 'NEW_CAR', 'USED_CAR', 'FURNITURE', 'RADIO/TV', 'EDUCATION', 'RETRAINING']]\n",
        "y_train = df['RESPONSE']\n",
        "\n",
        "# Display features and target variable\n",
        "print(\"\\nFeatures (First 5 rows):\")\n",
        "print(X_train.head())\n",
        "print(\"\\nTarget variable (First 5 rows):\")\n",
        "print(y_train.head())\n",
        "\n",
        "# Step 6: Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.1, random_state=9)\n",
        "\n",
        "# Display shapes of training and testing sets\n",
        "print(f\"\\nX_train shape: {X_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")\n",
        "\n",
        "# Step 7: Perform feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Display scaled training data\n",
        "print(\"\\nScaled Training Features (First 5 rows):\")\n",
        "print(X_train_scaled[:5])\n",
        "\n",
        "# Step 8: Define the parameter grid for hyperparameter tuning\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 250, 300],\n",
        "    'max_depth': [10, 15, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Step 9: Create the RandomForestClassifier\n",
        "random_forest_classifier = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
        "\n",
        "# Step 10: Instantiate the grid search with the RandomForestClassifier and parameter grid\n",
        "grid_search = GridSearchCV(random_forest_classifier, param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "# Step 11: Fit the grid search to the data\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Step 12: Get the best parameters\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "# Display best hyperparameters\n",
        "print(\"\\nBest Hyperparameters:\")\n",
        "print(best_params)\n",
        "\n",
        "# Step 13: Train the model with the best parameters\n",
        "best_random_forest_classifier = RandomForestClassifier(\n",
        "    n_estimators=best_params['n_estimators'],\n",
        "    max_depth=best_params['max_depth'],\n",
        "    min_samples_split=best_params['min_samples_split'],\n",
        "    min_samples_leaf=best_params['min_samples_leaf'],\n",
        "    class_weight='balanced',\n",
        "    random_state=42\n",
        ")\n",
        "best_random_forest_classifier.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Step 14: Make predictions on the test set\n",
        "y_pred = best_random_forest_classifier.predict(X_test_scaled)\n",
        "\n",
        "# Step 15: Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_report_result = classification_report(y_test, y_pred)\n",
        "\n",
        "# Display accuracy and classification report\n",
        "print(f\"\\nAccuracy: {accuracy}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report_result)\n",
        "\n",
        "# Step 16: Make predictions on the testing set\n",
        "testing_data_scaled = scaler.transform(testing_data[['CHK_ACCT', 'DURATION', 'HISTORY', 'NEW_CAR', 'USED_CAR', 'FURNITURE', 'RADIO/TV', 'EDUCATION', 'RETRAINING']])\n",
        "y_pred_testing = best_random_forest_classifier.predict(testing_data_scaled)\n",
        "\n",
        "# Step 17: Create a DataFrame with the predictions\n",
        "predictions_df = pd.DataFrame({'ID': testing_data['OBS_ID'], 'score_level': y_pred_testing})\n",
        "\n",
        "# Step 18: Save predictions to a CSV file\n",
        "predictions_df.to_csv('/submission.csv', index=False)\n",
        "\n",
        "# Step 19: Display the predictions DataFrame\n",
        "print(\"\\nPredictions on Testing Data (First 5 rows):\")\n",
        "print(predictions_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VzjcTDxAZ1mK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ZUmFRwW2bT94"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}